"""Nemesis test: strict integrity check for ISO Table B.1 retrieval/hydration."""

from __future__ import annotations

import json
from pathlib import Path

import pytest

from tests.evaluation.custom_metrics import TableCellExpectation, assert_markdown_table_match


@pytest.mark.parametrize("dataset_path", ["tests/evaluation/golden_dataset.json", "tests/evaluation/golden_dataset.example.json"])
def test_iso_table_b1_integrity(dataset_path: str) -> None:
    """Fail if hydrated markdown differs from expected Table B.1 structure/content."""

    path = Path(dataset_path)
    if not path.exists():
        pytest.skip(f"Dataset not found: {dataset_path}")

    payload = json.loads(path.read_text(encoding="utf-8"))
    items = payload if isinstance(payload, list) else payload.get("cases", [])

    case = next((item for item in items if item.get("id") == "iso_table_b1_integrity"), None)
    if case is None:
        pytest.skip("Nemesis case 'iso_table_b1_integrity' not present in dataset.")

    # `predicted_markdown_table` should be generated by the evaluation runner and
    # persisted into the dataset snapshot/artifact for deterministic regression checks.
    predicted = case.get("predicted_markdown_table")
    expected = case.get("expected", {}).get("markdown_table")
    key_cells = [
        TableCellExpectation(
            row=str(cell.get("row", "")),
            column=str(cell.get("column", "")),
            value=str(cell.get("value", "")),
        )
        for cell in case.get("expected", {}).get("key_cells", [])
    ]

    assert isinstance(predicted, str) and predicted.strip(), "predicted_markdown_table is required for nemesis test."
    assert isinstance(expected, str) and expected.strip(), "expected.markdown_table is required for nemesis test."
    assert_markdown_table_match(predicted=predicted, expected=expected, key_cells=key_cells)
